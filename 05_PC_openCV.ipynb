{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python Chilla:** Python Advanced\n",
    "\n",
    "**Name**: Arsalan Ali<br>\n",
    "**Email**: arslanchaos@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Chapter 23: Computer Vision\n",
    " ### **Topics Included:**<br>\n",
    " * Viewing an Image\n",
    " * Resizing an Image\n",
    " * Convert to grayscale\n",
    " * Convert to binary (black and white)\n",
    " * Saving an Image\n",
    " * Reading and Playing a Video\n",
    " * Converting Video to grayscale\n",
    " * Converting Video to binary\n",
    " * Saving the Video\n",
    " * Video Capture through Webcam\n",
    " * Convert Webcam to Grayscale and Binary\n",
    " * Saving Webcam Video\n",
    " * Change Camera/Video Settings\n",
    " * Basic Image Manipulation\n",
    " * Draw Shapes\n",
    " * Resolution and FPS of Camera\n",
    " * Saving HD recording of Cam-stream\n",
    " * Joining Two Images\n",
    " * Getting Co-ordinates and Colors of Image using Mouse Clicks\n",
    " * Image Perspective Warp, Flip and Rotation\n",
    " * Extracting frames from a Video\n",
    " * HSV Sliders\n",
    " * Face Detection on Image\n",
    " * Face Detection on Webcam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "img = cv.imread(\"resources/openCV_intro.jpg\")\n",
    "cv.imshow(\"My\", img)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.resize(img, (400,200))\n",
    "cv.imshow(\"My\", img)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "cv.imshow(\"My\", gray_img)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh, binary = cv.threshold(gray_img, 120,255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"My\", binary)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite(\"resources/grayscale.jpg\", gray_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Playing a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"resources/ergo.mp4\")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"error in YOUR VIDEO\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # ret is a boolean variable that returns true if the frame is available\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv.imshow(\"Video\", frame)\n",
    "\n",
    "    # Wait for keypress. The 0xFF is the key that we assigned as \"q\"\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() # It will release the memory (RAM) that the video uses\n",
    "cv.destroyAllWindows() # It'd close all windows created using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Video into Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"resources/ergo.mp4\")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"error in YOUR VIDEO\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # ret is a boolean variable that returns true if the frame is available\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # using same method for converting rgb image to grayscale\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv.imshow(\"Video\", grayframe)\n",
    "\n",
    "    # Wait for keypress. The 0xFF is the key that we assigned as \"q\"\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() # It will release the memory (RAM) that the video uses\n",
    "cv.destroyAllWindows() # It'd close all windows created using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Video into Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"resources/ergo.mp4\")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"error in YOUR VIDEO\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # ret is a boolean variable that returns true if the frame is available\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # using same method for converting rgb image to grayscale\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    thresh, binary = cv.threshold(grayframe, 120,255, cv.THRESH_BINARY)\n",
    "\n",
    "    cv.imshow(\"Video\", binary)\n",
    "\n",
    "    # Wait for keypress. The 0xFF is the key that we assigned as \"q\"\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() # It will release the memory (RAM) that the video uses\n",
    "cv.destroyAllWindows() # It'd close all windows created using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"resources/ergo.mp4\")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"error in YOUR VIDEO\")\n",
    "\n",
    "# Getting frame Width and Height and converting to Int\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# VIDEO WRITER DEFINITION\n",
    "# VideoWriter(filename, codec, frames per second, frame size, Colored)\n",
    "# filename: Input video file\n",
    "# fourcc: 4-character code of codec used to compress the frames\n",
    "# fps: framerate of videostream\n",
    "# framesize: Height and width of frame\n",
    "# isColor: If its colored then use 1 if not then 0\n",
    "out_mp4 = cv.VideoWriter('resources/proxy.mp4',cv.VideoWriter_fourcc(*'XVID'), 24, size, isColor=False)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # ret is a boolean variable that returns true if the frame is available\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Write the frame to the output files\n",
    "        out_mp4.write(grayframe)\n",
    "\n",
    "        # using same method for converting rgb image to grayscale\n",
    "        cv.imshow(\"Video\", grayframe)\n",
    "\n",
    "        # Wait for keypress. The 0xFF is the key that we assigned as \"q\"\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        \n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()  # It will release the memory (RAM) that the video uses\n",
    "out_mp4.release() # It'll stop the VideoWriter\n",
    "cv.destroyAllWindows() # It'd close all windows created using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture through Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# If webcam is Open then run this loop\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Get all the frames from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If the frames are not empty then do this\n",
    "    if ret == True:\n",
    "\n",
    "        # Show the webcam\n",
    "        cv.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Condition to stop webcam using \"q\" key\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    # If webcam is not Open then close the loop\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # It will release the memory (RAM) that the webcam uses\n",
    "cv.destroyAllWindows() # It'd close all windows created using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert Webcam to Grayscale and Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        thresh, binary = cv.threshold(grayframe, 120,255, cv.THRESH_BINARY)\n",
    "\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "        cv.imshow(\"GrayCam\", grayframe)\n",
    "        cv.imshow(\"Black&WhiteCam\", binary)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Webcam Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "web_mp4 = cv.VideoWriter('resources/web.mp4',cv.VideoWriter_fourcc(*'XVID'), 24, size, isColor=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "        web_mp4.write(frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "web_mp4.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Camera/Video settings\n",
    "* 0: Current position of the video file in milliseconds.\n",
    "\n",
    "* 1: 0-based index of the frame to be decoded/captured next.\n",
    "\n",
    "* 2: Relative position of the video file\n",
    "\n",
    "* 3: Width of the frames in the video stream.\n",
    "\n",
    "* 4: Height of the frames in the video stream.\n",
    "\n",
    "* 5: Frame rate.\n",
    "\n",
    "* 6: 4-character code of codec.\n",
    "\n",
    "* 7: Number of frames in the video file.\n",
    "\n",
    "* 8: Format of the Mat objects returned by retrieve()\n",
    "\n",
    "* 9: Backend-specific value indicating the current capture mode\n",
    "\n",
    "* 10: Brightness of the image (only for cameras)\n",
    "\n",
    "* 11: Contrast of the image (only for cameras)\n",
    "\n",
    "* 12: Saturation of the image (only for cameras)\n",
    "\n",
    "* 13: Hue of the image (only for cameras)\n",
    "\n",
    "* 14: Gain of the image (only for cameras)\n",
    "\n",
    "* 15: Exposure (only for cameras)\n",
    "\n",
    "* 16: Boolean flags indicating whether images should be converted to RGB.\n",
    "\n",
    "* 17: White Balance\n",
    "\n",
    "* 18: Rectification flag for stereo cameras\n",
    "\n",
    "* 19: Monochrome\n",
    "\n",
    "* 20: Sharpness\n",
    "\n",
    "* 21: Auto Exposure\n",
    "\n",
    "* 22: Gamma\n",
    "\n",
    "* 23: Temperature\n",
    "\n",
    "* 24: Trigger\n",
    "\n",
    "* 25: Trigger Delay\n",
    "\n",
    "* 26: White Balanced\n",
    "\n",
    "* 27: Zoom\n",
    "\n",
    "* 28: Focus\n",
    "\n",
    "* 29: GUID\n",
    "\n",
    "* 30: Speed\n",
    "\n",
    "* 32: Backlight\n",
    "\n",
    "* 33: Pan\n",
    "\n",
    "* 34: Tilt\n",
    "\n",
    "* 35: Roll\n",
    "\n",
    "* 36: Iris\n",
    "\n",
    "* 37: Popup settings\n",
    "\n",
    "* 38: Buffersize\n",
    "\n",
    "* 39: Autofocus\n",
    "\n",
    "* 40: Sample Aspect Ratio (num)\n",
    "\n",
    "* 41: Sample Aspect Ratio (den)\n",
    "\n",
    "* 42: Backend\n",
    "\n",
    "* 43: Channel\n",
    "\n",
    "* 44: Auto White Balance\n",
    "\n",
    "* 45: White Balance Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(10, 500) # Brightness Index (10), next is value parameter\n",
    "cap.set(3, 500) # Width\n",
    "cap.set(4, 900) # Height\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = cv.imread(\"resources/hills.jpg\")\n",
    "\n",
    "# resize\n",
    "resized_img = cv.resize(img, (350,350))\n",
    "\n",
    "# grayscale\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# blurred\n",
    "blur_img = cv.GaussianBlur(img, (7,7), 0)\n",
    "\n",
    "# edge detection\n",
    "edge_img = cv.Canny(img, 48,48)\n",
    "\n",
    "# thickness of lines\n",
    "mat_kernel = np.ones((3,3), np.uint8)\n",
    "dilated_img = cv.dilate(edge_img, mat_kernel, iterations=1)\n",
    "\n",
    "# thinner outlines\n",
    "ero_lines = cv.erode(dilated_img, mat_kernel, iterations=1)\n",
    "\n",
    "# cropped\n",
    "cropped_img = img[0:500, 0:500]\n",
    "\n",
    "while(True):\n",
    "    # cv.imshow(\"Original Hills\",img)\n",
    "    # cv.imshow(\"Resized Hills\",resized_img)\n",
    "    # cv.imshow(\"Grayscale Hills\",gray_img)\n",
    "    # cv.imshow(\"Blur Hills\",blur_img)\n",
    "    # cv.imshow(\"Edge Detection Hills\",edge_img)\n",
    "    cv.imshow(\"Dilated Hills\",dilated_img)\n",
    "    cv.imshow(\"Erosion Hills\",ero_lines)\n",
    "    cv.imshow(\"Cropped Hills\",cropped_img)\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of canvas is: (600, 600)\n"
     ]
    }
   ],
   "source": [
    "# Draw a canvas\n",
    "# canvas = np.zeros((600,600)) # black\n",
    "canvas = np.ones((600,600)) # white\n",
    "\n",
    "# print size\n",
    "print(f\"The size of canvas is: {canvas.shape}\")\n",
    "\n",
    "# color channel addition\n",
    "colored_canvas = np.zeros((600,600,3), np.uint8)\n",
    "\n",
    "# Color fill\n",
    "colored_canvas[:] = 0,150,255 \n",
    "\n",
    "# Part of Canvas getting colored\n",
    "colored_canvas[150:230, 100:120] = 255,0,0\n",
    "\n",
    "# Adding line\n",
    "cv.line(colored_canvas, (300,0), (300,600), (0,0,0), 3)\n",
    "\n",
    "# Adding another line\n",
    "cv.line(colored_canvas, (colored_canvas.min(),colored_canvas.min()), (colored_canvas.shape[0],colored_canvas.shape[0]), (0,0,0), 3)\n",
    "\n",
    "# Adding rectangles without fill\n",
    "cv.rectangle(colored_canvas, (50,100), (300,400), (255,255,255), 3)\n",
    "\n",
    "# Adding rectangles with fill\n",
    "cv.rectangle(colored_canvas, (50,100), (300,400), (255,255,255), cv.FILLED)\n",
    "\n",
    "# Adding Circle without fill\n",
    "cv.circle(colored_canvas, (500,400), 60, (0,0,255), 5)\n",
    "\n",
    "# Adding Circle with fill\n",
    "cv.circle(colored_canvas, (500,400), 60, (0,0,255), cv.FILLED)\n",
    "\n",
    "# Adding Text\n",
    "cv.putText(colored_canvas, f\"Python Chilla Codanics\", (0,400), cv.FONT_HERSHEY_SCRIPT_SIMPLEX,2,(0,0,0),1)\n",
    "\n",
    "while(True):\n",
    "    cv.imshow(\"Canvas\", colored_canvas)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "     break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution and FPS of Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "def hd_resolution():\n",
    "    cap.set(3, 1280) # Width\n",
    "    cap.set(4, 720)  # Height\n",
    "\n",
    "def sd_resolution():\n",
    "    cap.set(3, 640) # Width\n",
    "    cap.set(4, 480)  # Height\n",
    "\n",
    "def fhd_resolution():\n",
    "    cap.set(3, 1920) # Width\n",
    "    cap.set(4, 1080)  # Height\n",
    "\n",
    "def fps():\n",
    "    cap.set(5, 30) # Framerate\n",
    "\n",
    "\n",
    "sd_resolution()\n",
    "fps()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv.imshow(\"Camera\", frame)\n",
    "        if cv.waitKey(1) & 0xFF== ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving HD recording of Cam-stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "def hd_resolution():\n",
    "    cap.set(3, 1280) # Width\n",
    "    cap.set(4, 720)  # Height\n",
    "\n",
    "def fhd_resolution():\n",
    "    cap.set(3, 1920) # Width\n",
    "    cap.set(4, 1080)  # Height\n",
    "\n",
    "hd_resolution()\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "web_mp4 = cv.VideoWriter('resources/web_HD.mp4',cv.VideoWriter_fourcc(*'XVID'), 24, size, isColor=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "        web_mp4.write(frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "web_mp4.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Two Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"resources/hills.jpg\")\n",
    "img = cv.resize(img, (300,400))\n",
    "img2 = cv.imread(\"resources/openCV_intro.jpg\")\n",
    "\n",
    "# Stacking Same Size Images\n",
    "def stacking_same(img_1, img_2, stack):\n",
    "    if stack == \"h\":\n",
    "        horizontal = np.hstack((img_1, img_2))\n",
    "        cv.imshow(\"Horizontal\", horizontal)\n",
    "    else:\n",
    "        vertical = np.vstack((img_1, img_2))\n",
    "        cv.imshow(\"Vertical\", vertical)\n",
    "    \n",
    "    \n",
    "# Stacking Different Sized Images\n",
    "def stacking_diff(img1, img2, stack):\n",
    "    w1 = img1.shape[1]\n",
    "    w2 = img2.shape[1]\n",
    "    h1 = img1.shape[0]\n",
    "    h2 = img2.shape[0]\n",
    "    ww = max(w1, w2)\n",
    "    hh = max(h1, h2)\n",
    "    if stack == \"h\":\n",
    "        img1 = cv.copyMakeBorder(img1, 0, hh-h1, 0, 0, borderType=cv.BORDER_CONSTANT, value=(255,255,255,0))\n",
    "        img2 = cv.copyMakeBorder(img2, 0, hh-h2, 0, 0, borderType=cv.BORDER_CONSTANT, value=(255,255,255,0))\n",
    "        horizontal = cv.hconcat([img1, img2])\n",
    "        cv.imshow(\"Horizontal Image Stacking of Different Sizes\", horizontal)\n",
    "    else: \n",
    "        img1 = cv.copyMakeBorder(img1, 0, 0, 0, ww-w1, borderType=cv.BORDER_CONSTANT, value=(255,255,255,0))\n",
    "        img2 = cv.copyMakeBorder(img2, 0, 0, 0, ww-w2, borderType=cv.BORDER_CONSTANT, value=(255,255,255,0))\n",
    "        vertical = cv.vconcat([img1, img2])\n",
    "        cv.imshow(\"Vertical Image Stacking of Different Sizes\", vertical)\n",
    "\n",
    "\n",
    "stacking_same(img, img, \"h\")\n",
    "stacking_diff(img, img2, \"v\")\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Co-ordinates and Colors of Image using Mouse Click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117   109\n",
      "199   204\n",
      "294   135\n",
      "294   135\n",
      "228   285\n",
      "148   312\n",
      "234   407\n"
     ]
    }
   ],
   "source": [
    "# reading the image\n",
    "img = cv.imread(\"resources/perspective.jpg\")\n",
    "\n",
    "# displaying the image\n",
    "cv.imshow('image', img)\n",
    "\n",
    "def click_event(event, x, y, flags, params):\n",
    " \n",
    "    # checking for left mouse clicks\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    " \n",
    "        # displaying the coordinates on the Shell\n",
    "        print(x, ' ', y)\n",
    " \n",
    "        # displaying the coordinates on the image window\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(img, str(x) + ',' + str(y), (x,y), font, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # show text over image\n",
    "        cv.imshow('image', img)\n",
    "          \n",
    "    # checking for right mouse clicks      \n",
    "    elif event==cv.EVENT_RBUTTONDOWN:\n",
    " \n",
    "        # displaying the coordinates\n",
    "        print(x, ' ', y)\n",
    " \n",
    "        # displaying the coordinates\n",
    "        # on the image window\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        b = img[y, x, 0]\n",
    "        g = img[y, x, 1]\n",
    "        r = img[y, x, 2]\n",
    "        cv.putText(img, str(b) + ',' + str(g) + ',' + str(r), (x,y), font, 1, (255, 255, 0), 2)\n",
    "        cv.imshow('image', img)\n",
    "\n",
    "# calling the function\n",
    "cv.setMouseCallback('image', click_event)\n",
    "\n",
    "# wait for a key to be pressed to exit\n",
    "cv.waitKey(0)\n",
    "\n",
    "# close the window\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Perspective Warp, Flip and Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"resources/perspective.jpg\")\n",
    "\n",
    "# Defining Points\n",
    "point1 = np.float32([[107,93], [136,451], [319,84], [373,415]])\n",
    "width, height = 488, 485\n",
    "point2 = np.float32([[0,0], [width,0], [0, height], [width, height]])\n",
    "\n",
    "matrix = cv.getPerspectiveTransform(point1, point2)\n",
    "\n",
    "out_img = cv.warpPerspective(img, matrix, (width, height))\n",
    "image = cv.flip(out_img, 0)\n",
    "image = cv.rotate(image, cv.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "cv.imshow(\"Transformed Image\", image)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting frames from a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"resources/web.mp4\")\n",
    "\n",
    "frames = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # cv.imshow(\"Video\", frame)\n",
    "        cv.imwrite(f\"resources/frames/frame_{frames}.jpg\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    frames = frames+2\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV Sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# sliders position function\n",
    "def sliders(x):\n",
    "    # Declaring global variables for later use\n",
    "    global hue_min, hue_max, sat_min, sat_max, val_min, val_max\n",
    "\n",
    "    # Getting the values off the slider\n",
    "    hue_min = cv.getTrackbarPos(\"Hue Min\", \"Bars\")\n",
    "    hue_max = cv.getTrackbarPos(\"Hue Max\", \"Bars\")\n",
    "    sat_min = cv.getTrackbarPos(\"Sat Min\", \"Bars\")\n",
    "    sat_max = cv.getTrackbarPos(\"Sat Max\", \"Bars\")\n",
    "    val_min = cv.getTrackbarPos(\"Val Min\", \"Bars\")\n",
    "    val_max = cv.getTrackbarPos(\"Val Max\", \"Bars\")\n",
    "\n",
    "\n",
    "# Creating a new window for sliders\n",
    "cv.namedWindow(\"Bars\")\n",
    "cv.resizeWindow(\"Bars\", 550,300)\n",
    "\n",
    "# Temporary function to assign to tracker creation\n",
    "def temp(x):\n",
    "    pass\n",
    "\n",
    "# create trackbars for high,low H,S,V \n",
    "cv.createTrackbar(\"Hue Min\", \"Bars\", 0,179, temp)\n",
    "cv.createTrackbar(\"Hue Max\", \"Bars\", 179,179, temp)\n",
    "\n",
    "cv.createTrackbar(\"Sat Min\", \"Bars\", 0,255, temp)\n",
    "cv.createTrackbar(\"Sat Max\", \"Bars\", 255,255, temp)\n",
    "\n",
    "cv.createTrackbar(\"Val Min\", \"Bars\", 0,255, temp)\n",
    "cv.createTrackbar(\"Val Max\", \"Bars\", 255,255, temp)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    path = \"resources/sam.jpg\"\n",
    "\n",
    "    # reading image\n",
    "    img = cv.imread(path)\n",
    "\n",
    "    # resizing image\n",
    "    img = cv.resize(img,(640,480))\n",
    "\n",
    "    # Convert in HSV (Hue, Saturation, Value)\n",
    "    hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calling the slider position function to get slider values\n",
    "    sliders(2)\n",
    "\n",
    "    # HSV lows and highs\n",
    "    lower = np.array([hue_min, sat_min, val_min], np.uint8)\n",
    "    upper = np.array([hue_max, sat_max, val_max], np.uint8)\n",
    "\n",
    "    # Mask for HSV\n",
    "    mask_img = cv.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    # Masking selected color of HSV\n",
    "    out_img = cv.bitwise_and(img, img, mask=mask_img)\n",
    "\n",
    "    # Converting mask image to RGB so we can concatinate and show both together\n",
    "    mask_img = cv.cvtColor(mask_img,cv.COLOR_GRAY2BGR)\n",
    "    both = np.hstack((mask_img,out_img))\n",
    "    cv.imshow(\"Final Results\", both)\n",
    "\n",
    "\t# Waiting for window to remain till we press \"q\" to quit\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"resources/face.jpg\")\n",
    "img = cv.resize(img, (400,480))\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(\"resources/haarcascade_frontalcatface.xml\")\n",
    "\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray_img)\n",
    "\n",
    "# Draw a Rectangle\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 1)\n",
    "\n",
    "cv.imshow(\"Face\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection on Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(\"resources/haarcascade_frontalcatface.xml\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        gray_img = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img)\n",
    "        # Draw a Rectangle\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 1)\n",
    "        \n",
    "        cv.imshow(\"OriginalCam\", frame)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
